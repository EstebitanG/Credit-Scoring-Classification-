# Reflexiones finales

Luego de haber finalizado este proyecto de credit scoring usando herramientas estadísticas y de Machine Learning, puedo rescatar los siguientes aprendizajes:

Nuevamente pude poner en práctica mis conocimientos en Python, aprendiendo nuevos comandos y herramientas que antes no conocía (como SMOTE para tratar el desbalance de clases, joblib para guardar los modelos entrenados y no perder tiempo en futuras implementaciones, y código usado para el preprocesamiento de datos en general). A su vez, pude cumplir a cabalidad con las etapas de un proyecto de análisis y ciencia de datos, desde el preprocesamiento y limpieza inicial, análisis exploratorio, entrenamiento de modelos y su aplicación.

El punto fuerte de este proyecto que representó el gran desafío fue justamente su primera parte, el preprocesamiento y limpieza. Fueron horas y horas invertidas para manejar múltiples registros problemáticos cumpliendo el gran desafío de perder la menor cantidad de información posible. Y es que en la fase de preprocesamiento y exploración, me di cuenta que el dataset de entrenamiento y dataset de testeo correspondían a datos de panel: registros de la misma persona en distintos momentos del tiempo, para estudiar su evolución. En este caso, hablamos de personas que tanto sus variables sociodemográficas como comportamiento de crédito variaba con el tiempo (meses en nuestro caso) y que por ende su clasificación crediticia en el entrenamiento podía cambiar. Uno a simple vista puede interpretar esta situación como registros duplicados, pero mi decisión fue mantener la mayor cantidad de registros posibles para que los modelos tengan más información de entrenamiento. El desafío estuvo en los outliers y valores incoherentes de los registros, y poder imputarlos con la lógica de sus duplicados (información estática como Occupation). Al mismo tiempo, esto se dió entre dataframes, donde se tuvo que importar este tipo de información desde el entrenamiento, algo que no representa sesgo a los modelos. Fue necesario diagnostiscar y depurar posteriormente errores en la limpieza para mantener la coherencia de los datos sin perderlos. Por lo tanto esta etapa me exigió un nivel de minuciosidad que no había aplicado nunca antes en ningún proyecto de Data Analitycs. Sin embargo, aún tengo mucho que aprender.

Además, ahondo tanto conceptualmente como en la implementación de los modelos de clasificación. Sensibilizo sus parámetros para llegar al mejor modelo posible en base a las métricas de evaluación mediante validación cruzada. Aplico tanto modelos básicos como modelos más potentes y populares en la industria para resolver el problema de clasificación, teniendo diversos resultados con distintas interpretaciones (expuestas en el proyecto).

Finalmente, puedo destacar que la finalización de este proyecto logra una mejoría en mi entendimiento del problema de Clasificación en Machine Learning, sus aplicaciones prácticas, y los desafíos respecto a las demás temáticas del área (Regresión y Agrupación - Clustering).
